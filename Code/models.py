# -*- coding: utf-8 -*-
"""Models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LRR838gKNzqDQnhZuyww0-qR79BdW5ye
"""

# This class is to build and evaluate different models (without data cleaning).
# The 4 models evaluated are Logistic Regression, K Nearest Neighbor (KNN), Decision Tree, and Random Forest (+ Baseline)

# Import required packages
import numpy as np
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline 
np.random.seed = 0

# put your imports here
import datapreparation
import modelsfunctions
from datapreparation import *
from modelsfunctions import *


# Import the training and testing data
X_train = datapreparation.X_train
y_train = datapreparation.y_train
X_test = datapreparation.X_test
y_test = datapreparation.y_test
X = datapreparation.X
y = datapreparation.y 


# 0. Baseline 
print("--------------------------------Baseline-------------------------------")
baseline_accuracy = get_baseline_accuracy(X, y)
print('Baseline accuracy: ', baseline_accuracy, '\n \n')


# 1. Logistic Regression
print("--------------------------Logistic Regression--------------------------")
from sklearn.linear_model import LogisticRegression
logreg = Pipeline([
    ('vectorizer_tfidf', TfidfVectorizer()),
    ('LR', LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=3000, random_state=50))
])
logreg.fit(X_train, y_train)
# Predictions
y_pred_lr = logreg.predict(X_test)
# Results of Logistic Regression
print("\n -----------------Classification Report------------------")
print(classification_report(y_test, y_pred_lr)) 
# Plotting confusion matrix for Logistic Regression
print("\n -------------------Confusion Matrix------------------ \n")
plot_confusion_matrix(y_test, y_pred_lr)
# Showing erroneous predictions
print("\n -----------Erroneous Predictions on test data-----------")
errors = get_errors(y_test, y_pred_lr, X_test)
print(errors) 
# Predicting on the unlabeled dataset
print("\n -------------Predictions on unlabeled data--------------")
predictions_lr = make_predictions(df_pred, logreg)
print(predictions_lr, '\n \n')



# 2. KNN
print("----------------------------------KNN----------------------------------")
from sklearn.neighbors import KNeighborsClassifier 
knn_clf = Pipeline([
    ('vectorizer_tfidf', TfidfVectorizer()),
    ('KNN', KNeighborsClassifier(n_neighbors=5))
]) 
knn_clf.fit(X_train, y_train)  
# Predictions
y_pred_knn = knn_clf.predict(X_test) 
# Results of KNN
print("\n -----------------Classification Report------------------")
print(classification_report(y_test, y_pred_knn))  
# Plotting confusion matrix for KNN
print("\n -------------------Confusion Matrix------------------ \n")
plot_confusion_matrix(y_test, y_pred_knn)
# Showing erroneous predictions 
print("\n -----------Erroneous Predictions on test data-----------")
errors = get_errors(y_test, y_pred_knn, X_test)
print(errors) 
# Predicting on the unlabeled dataset
print("\n -------------Predictions on unlabeled data--------------")
predictions_knn = make_predictions(df_pred, knn_clf)
print(predictions_knn, '\n \n') 



# 3. Decision Tree
print("-------------------------------Decision Tree---------------------------")
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import GridSearchCV
grid = {'max_depth':np.arange(1,25)}
tree = DecisionTreeClassifier(random_state=50)
dt_clf = Pipeline([
    ('vectorizer_tfidf', TfidfVectorizer()),
    ('TREE', GridSearchCV(tree, grid, cv=5))
])
dt_clf.fit(X_train, y_train)
# Predictions
y_pred_dt = dt_clf.predict(X_test) 
# Results of Decision Tree
print("\n -----------------Classification Report------------------")
print(classification_report(y_test, y_pred_dt)) 
# Plotting confusion matrix for Decision Tree
print("\n -------------------Confusion Matrix------------------ \n")
plot_confusion_matrix(y_test, y_pred_dt)
# Showing erroneous predictions
print("\n -----------Erroneous Predictions on test data-----------")
errors = get_errors(y_test, y_pred_dt, X_test)
print(errors) 
# Predicting on the unlabeled dataset
print("\n -------------Predictions on unlabeled data--------------")
predictions_dt = make_predictions(df_pred, dt_clf) 
print(predictions_dt, '\n \n')



# 4. Random Forest
print("-----------------------------Random Forest-----------------------------")
from sklearn.ensemble import RandomForestClassifier
rfc_clf = Pipeline([
    ('vectorizer_tfidf', TfidfVectorizer()),
    ('RFC', RandomForestClassifier(random_state=50))
]) 
rfc_clf.fit(X_train, y_train)
# Predictions
y_pred_rfc = rfc_clf.predict(X_test)
# Results of Random Forest
print("\n -----------------Classification Report------------------")
print(classification_report(y_test, y_pred_rfc)) 
# Plotting confusion matrix for Random Forest
print("\n -------------------Confusion Matrix------------------ \n")
plot_confusion_matrix(y_test, y_pred_rfc)
#Showing erroneous predictions
print("\n -----------Erroneous Predictions on test data-----------")
errors = get_errors(y_test, y_pred_rfc, X_test)
print(errors) 
# Predicting on the unlabeled dataset
print("\n -------------Predictions on unlabeled data--------------")
predictions_rfc = make_predictions(df_pred, rfc_clf)
print(predictions_rfc, '\n \n')
# -*- coding: utf-8 -*-
"""BERTFunctions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y5xatDU0-kQLl0KcLlCYpP4TqtTEFYDW
"""

# Import required packages 
import tensorflow_hub as hub
from keras import backend as K

# This function calculates the balanced recall metric: recall = TP / (TP + FN)
def balanced_recall(y_true, y_pred):
    recall_by_class = 0
    # iterate over each predicted class to get class-specific metric
    for i in range(y_pred.shape[1]):
        y_pred_class = y_pred[:, i]
        y_true_class = y_true[:, i]
        true_positives = K.sum(K.round(K.clip(y_true_class * y_pred_class, 0, 1)))
        possible_positives = K.sum(K.round(K.clip(y_true_class, 0, 1)))
        recall = true_positives / (possible_positives + K.epsilon())
        recall_by_class = recall_by_class + recall
    return recall_by_class / y_pred.shape[1]

# This function calculates the balanced precision metric: precision = TP / (TP + FP)
def balanced_precision(y_true, y_pred):
    precision_by_class = 0
    # iterate over each predicted class to get class-specific metric
    for i in range(y_pred.shape[1]):
        y_pred_class = y_pred[:, i]
        y_true_class = y_true[:, i]
        true_positives = K.sum(K.round(K.clip(y_true_class * y_pred_class, 0, 1)))
        predicted_positives = K.sum(K.round(K.clip(y_pred_class, 0, 1)))
        precision = true_positives / (predicted_positives + K.epsilon())
        precision_by_class = precision_by_class + precision
    # return average balanced metric for each class
    return precision_by_class / y_pred.shape[1]

# This function calculates the F1 score metric
def balanced_f1_score(y_true, y_pred):
    precision = balanced_precision(y_true, y_pred)
    recall = balanced_recall(y_true, y_pred)
    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))

# This is a function wrapping model.predict and returning a numpy.ndarray of size 6 (as we have 6 classes) 
def predict_class(sentences):
  '''predict class of input text
  Args:
    - Sentences (list of strings)
  Output:
    - class (list of int)
  '''
  return [np.argmax(pred) for pred in model.predict(sentences)]

# Mapping difficulty for the unlabeled data
def map_difficulty(df, column):
  for i in range(df.shape[0]):
    if df[column].iloc[i] == 1:
      df[column].iloc[i] = 'A1'
    if df[column].iloc[i] == 2:
      df[column].iloc[i] = 'A2'
    if df[column].iloc[i] == 3:
      df[column].iloc[i] = 'B1'
    if df[column].iloc[i] == 4:
      df[column].iloc[i] = 'B2'
    if df[column].iloc[i] == 5:
      df[column].iloc[i] = 'C1'
    if df[column].iloc[i] == 6:
      df[column].iloc[i] = 'C2'
  return df